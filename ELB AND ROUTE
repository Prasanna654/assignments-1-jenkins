
AWS Solutions Architect Training
Problem Statement:
You work for XYZ Corporation that uses on premise solutions and a limited
number of systems. With the increase in requests in their application, the load
also increases. So, to handle the load the corporation has to buy more systems
almost on a regular basis. Realizing the need to cut down the expenses on
systems, they decided to move their infrastructure to AWS.
Tasks To Be Performed:
1. Manage the scaling requirements of the company by:
a. Deploying multiple compute resources on the cloud as soon as the
load increases and the CPU utilization exceeds 80%
b. Removing the resources when the CPU utilization goes under 60%
2. Create a load balancer to distribute the load between compute resources.
3. Route the traffic to the company domain

ChatGPT said:
Here's a simple and clear step-by-step guide to complete the given tasks for XYZ Corporation's migration to AWS. This solution meets the need to scale automatically, balance load, and route traffic to the company domain.

✅ Overview of What You'll Build:
Auto Scaling Group: Automatically adds/removes EC2 instances based on CPU.

Load Balancer (ALB): Distributes traffic to all EC2 instances.

Route 53 DNS: Routes traffic from your company domain to the Load Balancer.

🔧 TASK 1: Manage Scaling Requirements
Step 1.1: Create a Launch Template
Go to EC2 Console → Launch Templates → Create Launch Template

Fill in:

Name: xyz-launch-template

AMI: Amazon Linux 2 (or your custom image)

Instance type: t3.micro (Free tier eligible)

Key pair: Select your SSH key

Security group: Allow ports 22 (SSH), 80 (HTTP)

(Optional) Add startup script in User data

Step 1.2: Create an Auto Scaling Group (ASG)
Go to EC2 Console → Auto Scaling Groups → Create

Choose the Launch Template you just created.

Select 2 availability zones for high availability.

Set:

Desired capacity: 2

Min capacity: 1

Max capacity: 5

Under Target Tracking Scaling Policy:

Choose metric: Average CPU Utilization

Set target value: 70%

AWS will now:

Add instances if CPU > 80%

Remove instances if CPU < 60%

🌐 TASK 2: Create a Load Balancer
Step 2.1: Create an Application Load Balancer (ALB)
Go to EC2 Console → Load Balancers → Create Load Balancer

Choose Application Load Balancer

Set:

Name: xyz-alb

Scheme: internet-facing

Listener: HTTP (port 80)

Add 2 public subnets

Create a new security group that allows HTTP from 0.0.0.0/0

Create a Target Group:

Type: Instance

Protocol: HTTP

Port: 80

Health check path: / or your app path

Link the Auto Scaling Group to this Target Group

Now, the Load Balancer will automatically send traffic to all healthy EC2 instances.

🌍 TASK 3: Route Traffic to Company Domain
Step 3.1: Use Route 53 to Route Domain Traffic
Go to Route 53 Console → Hosted Zones

Create a Hosted Zone for your domain (e.g., xyzcorp.com)

Or if you already have a domain, just manage the records

Create a Record Set:

Type: A (Alias)

Alias Target: Select your ALB DNS Name

Save the record

💡 Your domain (e.g., www.xyzcorp.com) will now point to your Load Balancer and route traffic to your EC2 instances.

🔐 Security Configuration Recap
Resource	Allowed Ports	Source
Load Balancer	80 (HTTP)	0.0.0.0/0
EC2 Instances	80 (from ALB), 22 (SSH)	ALB SG, Admin IP

🧪 Test Your Setup
Open your domain name in the browser (or ALB DNS name if no domain yet).

You should see your web app (or test page).

Use a CPU stress test on EC2 instances to simulate load and watch autoscaling.

✅ Summary
Task	Service Used	Completed
Auto scaling based on CPU	EC2, Auto Scaling, CloudWatch	✅
Load distribution	Application Load Balancer (ALB)	✅
Domain routing	Route 53	✅

Would you like me to help you:

Write a Terraform script to automate this?

Provide a diagram showing the setup?

Help you simulate CPU load for testing?

Let me know!



You said:
yes

ChatGPT said:
Great! Since you said yes, here’s what I’ll provide for you:

✅ Part 1: Diagram – AWS Architecture Overview
This architecture includes:

Auto Scaling Group (EC2)

Application Load Balancer

Route 53 for DNS

Security groups and scaling policies

lua
Copy
Edit
           +------------------------+
           |   Route 53 (DNS)       |
           | xyzcorp.com            |
           +-----------+------------+
                       |
                       v
          +---------------------------+
          |  Application Load Balancer|
          |    (HTTP on port 80)      |
          +-----------+---------------+
                      |
     +----------------+------------------+
     |                |                  |
     v                v                  v
+--------+       +--------+        +--------+
| EC2-1  |       | EC2-2  |  ...   | EC2-N  |
| (Auto  |       | (Auto  |        | (Auto  |
| Scale) |       | Scale) |        | Scale) |
+--------+       +--------+        +--------+
✅ Auto Scaling Group adjusts EC2 count based on CPU
✅ Load Balancer distributes incoming traffic
✅ Route 53 maps your domain to the ALB

✅ Part 2: Terraform Script
This is a basic setup to get you started with infrastructure as code:

Note: You’ll need to adjust things like AMI ID, Key Pair name, region, etc.

🔧 main.tf
hcl
Copy
Edit
provider "aws" {
  region = "us-east-1"
}

resource "aws_launch_template" "web" {
  name_prefix   = "xyz-launch-template"
  image_id      = "ami-0c02fb55956c7d316"  # Amazon Linux 2 AMI (update as needed)
  instance_type = "t3.micro"
  key_name      = "your-key-name"

  user_data = base64encode(<<EOF
#!/bin/bash
sudo yum update -y
sudo yum install -y httpd
sudo systemctl start httpd
sudo systemctl enable httpd
echo "<h1>Welcome to XYZ Corp</h1>" > /var/www/html/index.html
EOF
  )
}

resource "aws_security_group" "asg_sg" {
  name        = "asg-security-group"
  description = "Allow HTTP and SSH"
  vpc_id      = "your-vpc-id"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["your-ip/32"]  # your admin IP
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_autoscaling_group" "asg" {
  desired_capacity     = 2
  max_size             = 5
  min_size             = 1
  vpc_zone_identifier  = ["subnet-xxxxxxxx", "subnet-yyyyyyyy"] # Replace with your public subnet IDs
  launch_template {
    id      = aws_launch_template.web.id
    version = "$Latest"
  }

  target_group_arns = [aws_lb_target_group.app_tg.arn]
  health_check_type = "EC2"
}

resource "aws_lb" "app_lb" {
  name               = "xyz-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.asg_sg.id]
  subnets            = ["subnet-xxxxxxxx", "subnet-yyyyyyyy"] # Replace with your public subnet IDs
}

resource "aws_lb_target_group" "app_tg" {
  name     = "xyz-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = "your-vpc-id"
}

resource "aws_lb_listener" "front_end" {
  load_balancer_arn = aws_lb.app_lb.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app_tg.arn
  }
}
✅ Part 3: Testing CPU Scaling
Once deployed, SSH into an EC2 instance and run:

bash
Copy
Edit
sudo yum install -y stress
stress --cpu 2 --timeout 300
This causes high CPU usage → triggers Auto Scaling to add more instances.

✅ Part 4: Route 53 Configuration
After ALB is set up:

Go to Route 53

Create or use existing Hosted Zone (e.g. xyzcorp.com)

Create A Record

Name: www.xyzcorp.com

Type: A – Alias

Alias target: your ALB DNS name

✅ Now when users go to www.xyzcorp.com, AWS routes it to the load balancer → autoscaled EC2s

Would you like help setting this up in
